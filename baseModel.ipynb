{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6be35e-aaf8-4750-93e5-f4076ba7a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d390de7-1a10-486f-817e-a098bd51b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e0cead-4501-4614-8b39-3ec47cdfd09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>TQL</th>\n",
       "      <th>SQL</th>\n",
       "      <th>dataset</th>\n",
       "      <th>fileName</th>\n",
       "      <th>filePath</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_management</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>train</td>\n",
       "      <td>department_management.sqlite</td>\n",
       "      <td>sqliteDB/department_management.sqlite</td>\n",
       "      <td>{'count(*)': {0: 5}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   db_id                                                TQL  \\\n",
       "0  department_management  How many heads of the departments are older th...   \n",
       "\n",
       "                                          SQL dataset  \\\n",
       "0  SELECT count(*) FROM head WHERE age  >  56   train   \n",
       "\n",
       "                       fileName                               filePath  \\\n",
       "0  department_management.sqlite  sqliteDB/department_management.sqlite   \n",
       "\n",
       "                 result  \n",
       "0  {'count(*)': {0: 5}}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_id</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_name_original</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>column_list</th>\n",
       "      <th>column_list_original</th>\n",
       "      <th>column_datatypes</th>\n",
       "      <th>foreign_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perpetrator</td>\n",
       "      <td>perpetrator</td>\n",
       "      <td>perpetrator</td>\n",
       "      <td>Perpetrator_ID</td>\n",
       "      <td>['perpetrator id', 'people id', 'date', 'year'...</td>\n",
       "      <td>['Perpetrator_ID', 'People_ID', 'Date', 'Year'...</td>\n",
       "      <td>['number', 'number', 'text', 'number', 'text',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perpetrator</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>People_ID</td>\n",
       "      <td>['people id', 'name', 'height', 'weight', 'hom...</td>\n",
       "      <td>['People_ID', 'Name', 'Height', 'Weight', 'Hom...</td>\n",
       "      <td>['number', 'text', 'number', 'number', 'text']</td>\n",
       "      <td>[['perpetrator', 'People_ID', 'people', 'Peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     schema_id   table_name table_name_original     primary_key  \\\n",
       "0  perpetrator  perpetrator         perpetrator  Perpetrator_ID   \n",
       "1  perpetrator       people              people       People_ID   \n",
       "\n",
       "                                         column_list  \\\n",
       "0  ['perpetrator id', 'people id', 'date', 'year'...   \n",
       "1  ['people id', 'name', 'height', 'weight', 'hom...   \n",
       "\n",
       "                                column_list_original  \\\n",
       "0  ['Perpetrator_ID', 'People_ID', 'Date', 'Year'...   \n",
       "1  ['People_ID', 'Name', 'Height', 'Weight', 'Hom...   \n",
       "\n",
       "                                    column_datatypes  \\\n",
       "0  ['number', 'number', 'text', 'number', 'text',...   \n",
       "1     ['number', 'text', 'number', 'number', 'text']   \n",
       "\n",
       "                                        foreign_keys  \n",
       "0                                                 []  \n",
       "1  [['perpetrator', 'People_ID', 'people', 'Peopl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queryData = pd.read_csv('gs://data_tql/spider/processed/spiderQueryData.csv')\n",
    "tableData = pd.read_csv('gs://data_tql/spider/processed/Schemas/tablesSchemaSpider.csv')\n",
    "\n",
    "display(queryData.head(1))\n",
    "display(tableData.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bdd497-3c7c-42a2-809a-0f96a981a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema_natural_language(row):\n",
    "\n",
    "    schema_id = row['schema_id']\n",
    "    table_name = row['table_name']\n",
    "    primary_key = row['primary_key']\n",
    "    column_list = eval(row['column_list_original'])\n",
    "    datatype_list = eval(row['column_datatypes'])\n",
    "    foreign_key = eval(row['foreign_keys'])\n",
    "\n",
    "    column_list_with_datatype = []\n",
    "    for column, datatype in zip(column_list, datatype_list):\n",
    "        column_list_with_datatype.append(' has datatype '.join([column, datatype]))\n",
    "\n",
    "    schema_natural_language = f\"Given the Table {table_name} having columns as {', '.join(column_list_with_datatype)} which has {primary_key}\"\n",
    "    return schema_natural_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57110a2-994a-41dc-9f00-0905aa888101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How many heads of the departments are older than 56 ? Given the Table department having columns as Department_ID has datatype number, Name has datatype text, Creation has datatype text, Ranking has datatype number, Budget_in_Billions has datatype number, Num_Employees has datatype number which has Department_ID and Given the Table head having columns as head_ID has datatype number, name has datatype text, born_state has datatype text, age has datatype number which has head_ID and Given the Table management having columns as department_ID has datatype number, head_ID has datatype number, temporary_acting has datatype text which has department_ID',\n",
       " 'SELECT count(*) FROM head WHERE age  >  56')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableData['schema_natural_language'] = tableData.apply(create_schema_natural_language, axis = 1)\n",
    "tableData.head(3)\n",
    "\n",
    "all_schemas = tableData['schema_id'].unique()\n",
    "schema_table_query = {}\n",
    "for schema in all_schemas:\n",
    "    schema_details = ' and '.join(tableData[tableData['schema_id'] == schema]['schema_natural_language'].values)\n",
    "    schema_table_query[schema] = schema_details\n",
    "\n",
    "queryData['schema_natural_language'] = queryData['db_id'].map(schema_table_query)\n",
    "queryData['final_TQL'] = queryData['TQL'] + ' ' + queryData['schema_natural_language']\n",
    "queryData.head(2)\n",
    "\n",
    "queryData['final_TQL'][0], queryData['SQL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df4aefe3-4f6e-4de0-b942-ddd9efff6f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "192a2cd6-0331-4eab-84fc-3ac081e7fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for training\n",
    "class SQLDataset(Dataset):\n",
    "    def __init__(self, input_texts, target_queries, tokenizer, task_prefix):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_queries = target_queries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.task_prefix = task_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_text = self.task_prefix + self.input_texts[index]\n",
    "        target_query = self.target_queries[index]\n",
    "\n",
    "        input_encoding = self.tokenizer([input_text], return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        target_encoding = self.tokenizer([target_query], return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.squeeze(0),\n",
    "            'attention_mask': input_encoding.attention_mask.squeeze(0),\n",
    "            'labels': target_encoding.input_ids.squeeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60f7d609-cbde-46d0-935c-a39118708144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled dataset\n",
    "input_texts = queryData['final_TQL'].values # List of input texts\n",
    "target_queries = queryData['SQL'].values  # List of corresponding target SQL queries\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_input_texts, val_input_texts, train_target_queries, val_target_queries = train_test_split(input_texts, target_queries, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff750c0a-5be6-466f-9577-efae403074fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the custom dataset\n",
    "task_prefix = 'Generate an SQL Query for '\n",
    "train_dataset = SQLDataset(train_input_texts, train_target_queries, tokenizer, task_prefix)\n",
    "val_dataset = SQLDataset(val_input_texts, val_target_queries, tokenizer, task_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c277ade-2403-4a3a-be4d-a55ab8a45701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec231dca-c416-4bc1-9f5c-ab598ca23098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a5afd-0be9-4ebd-b8fb-217a3c2e7b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/122 [00:16<34:03, 16.89s/it]\u001b[A\n",
      "  2%|▏         | 2/122 [00:34<34:10, 17.09s/it]\u001b[A\n",
      "  2%|▏         | 3/122 [00:49<32:14, 16.26s/it]\u001b[A\n",
      "  3%|▎         | 4/122 [01:06<32:18, 16.43s/it]\u001b[A\n",
      "  4%|▍         | 5/122 [01:22<32:12, 16.52s/it]\u001b[A\n",
      "  5%|▍         | 6/122 [01:40<32:38, 16.89s/it]\u001b[A\n",
      "  6%|▌         | 7/122 [01:57<32:36, 17.02s/it]\u001b[A\n",
      "  7%|▋         | 8/122 [02:14<32:31, 17.12s/it]\u001b[A\n",
      "  7%|▋         | 9/122 [02:33<33:01, 17.53s/it]\u001b[A\n",
      "  8%|▊         | 10/122 [02:51<33:16, 17.83s/it]\u001b[A\n",
      "  9%|▉         | 11/122 [03:10<33:12, 17.95s/it]\u001b[A\n",
      " 10%|▉         | 12/122 [03:28<33:06, 18.06s/it]\u001b[A\n",
      " 11%|█         | 13/122 [03:47<33:35, 18.49s/it]\u001b[A\n",
      " 11%|█▏        | 14/122 [04:07<33:50, 18.80s/it]\u001b[A\n",
      " 12%|█▏        | 15/122 [04:24<32:50, 18.41s/it]\u001b[A\n",
      " 13%|█▎        | 16/122 [04:44<33:13, 18.81s/it]\u001b[A\n",
      " 14%|█▍        | 17/122 [05:05<33:49, 19.32s/it]\u001b[A\n",
      " 15%|█▍        | 18/122 [05:27<34:49, 20.10s/it]\u001b[A\n",
      " 16%|█▌        | 19/122 [05:46<34:21, 20.02s/it]\u001b[A\n",
      " 16%|█▋        | 20/122 [06:05<33:12, 19.53s/it]\u001b[A\n",
      " 17%|█▋        | 21/122 [06:25<32:59, 19.60s/it]\u001b[A\n",
      " 18%|█▊        | 22/122 [06:45<32:58, 19.79s/it]\u001b[A\n",
      " 19%|█▉        | 23/122 [07:04<32:36, 19.76s/it]\u001b[A\n",
      " 20%|█▉        | 24/122 [07:26<33:21, 20.42s/it]\u001b[A\n",
      " 20%|██        | 25/122 [07:46<32:34, 20.15s/it]\u001b[A\n",
      " 21%|██▏       | 26/122 [08:06<32:23, 20.24s/it]\u001b[A\n",
      " 22%|██▏       | 27/122 [08:28<32:47, 20.71s/it]\u001b[A\n",
      " 23%|██▎       | 28/122 [08:49<32:25, 20.70s/it]\u001b[A\n",
      " 24%|██▍       | 29/122 [09:09<31:36, 20.39s/it]\u001b[A\n",
      " 25%|██▍       | 30/122 [09:29<31:06, 20.29s/it]\u001b[A\n",
      " 25%|██▌       | 31/122 [09:49<30:35, 20.17s/it]\u001b[A\n",
      " 26%|██▌       | 32/122 [10:09<30:33, 20.37s/it]\u001b[A\n",
      " 27%|██▋       | 33/122 [10:31<30:37, 20.64s/it]\u001b[A\n",
      " 28%|██▊       | 34/122 [10:50<29:51, 20.36s/it]\u001b[A\n",
      " 29%|██▊       | 35/122 [11:09<28:34, 19.71s/it]\u001b[A\n",
      " 30%|██▉       | 36/122 [11:28<28:11, 19.67s/it]\u001b[A\n",
      " 30%|███       | 37/122 [11:49<28:29, 20.11s/it]\u001b[A\n",
      " 31%|███       | 38/122 [12:10<28:20, 20.25s/it]\u001b[A\n",
      " 32%|███▏      | 39/122 [12:30<27:49, 20.12s/it]\u001b[A\n",
      " 33%|███▎      | 40/122 [12:50<27:39, 20.24s/it]\u001b[A\n",
      " 34%|███▎      | 41/122 [13:12<27:48, 20.60s/it]\u001b[A\n",
      " 34%|███▍      | 42/122 [13:32<27:34, 20.69s/it]\u001b[A\n",
      " 35%|███▌      | 43/122 [13:52<26:39, 20.25s/it]\u001b[A\n",
      " 43%|████▎     | 52/122 [16:55<23:54, 20.50s/it]\u001b[A\n",
      " 43%|████▎     | 53/122 [17:13<22:44, 19.77s/it]\u001b[A\n",
      " 44%|████▍     | 54/122 [17:33<22:33, 19.91s/it]\u001b[A\n",
      " 45%|████▌     | 55/122 [17:54<22:35, 20.24s/it]\u001b[A\n",
      " 46%|████▌     | 56/122 [18:15<22:16, 20.25s/it]\u001b[A\n",
      " 47%|████▋     | 57/122 [18:35<22:10, 20.47s/it]\u001b[A\n",
      " 48%|████▊     | 58/122 [18:57<22:15, 20.86s/it]\u001b[A\n",
      " 48%|████▊     | 59/122 [19:17<21:32, 20.51s/it]\u001b[A\n",
      " 49%|████▉     | 60/122 [19:38<21:13, 20.55s/it]\u001b[A\n",
      " 50%|█████     | 61/122 [19:58<20:59, 20.64s/it]\u001b[A\n",
      " 65%|██████▍   | 79/122 [25:57<14:10, 19.77s/it]\u001b[A\n",
      " 66%|██████▌   | 80/122 [26:18<14:04, 20.12s/it]\u001b[A\n",
      " 66%|██████▋   | 81/122 [26:36<13:27, 19.68s/it]\u001b[A\n",
      " 67%|██████▋   | 82/122 [26:56<13:12, 19.80s/it]\u001b[A\n",
      " 68%|██████▊   | 83/122 [27:17<13:00, 20.01s/it]\u001b[A\n",
      " 69%|██████▉   | 84/122 [27:38<12:50, 20.29s/it]\u001b[A\n",
      " 76%|███████▌  | 93/122 [30:41<09:44, 20.15s/it]\u001b[A\n",
      " 77%|███████▋  | 94/122 [31:02<09:28, 20.31s/it]\u001b[A\n",
      " 78%|███████▊  | 95/122 [31:23<09:13, 20.51s/it]\u001b[A\n",
      " 79%|███████▊  | 96/122 [31:44<08:56, 20.63s/it]\u001b[A\n",
      " 80%|███████▉  | 97/122 [32:01<08:14, 19.76s/it]\u001b[A\n",
      " 80%|████████  | 98/122 [32:23<08:04, 20.20s/it]\u001b[A\n",
      " 81%|████████  | 99/122 [32:43<07:44, 20.22s/it]\u001b[A\n",
      " 82%|████████▏ | 100/122 [33:02<07:17, 19.90s/it]\u001b[A\n",
      " 83%|████████▎ | 101/122 [33:22<06:56, 19.84s/it]\u001b[A\n",
      " 84%|████████▎ | 102/122 [33:41<06:32, 19.60s/it]\u001b[A\n",
      " 84%|████████▍ | 103/122 [34:02<06:20, 20.04s/it]\u001b[A\n",
      " 85%|████████▌ | 104/122 [34:23<06:05, 20.29s/it]\u001b[A\n",
      " 86%|████████▌ | 105/122 [34:43<05:45, 20.32s/it]\u001b[A\n",
      " 87%|████████▋ | 106/122 [35:03<05:24, 20.29s/it]\u001b[A\n",
      " 88%|████████▊ | 107/122 [35:23<05:03, 20.22s/it]\u001b[A\n",
      " 89%|████████▊ | 108/122 [35:41<04:30, 19.35s/it]\u001b[A\n",
      " 89%|████████▉ | 109/122 [36:01<04:13, 19.50s/it]\u001b[A\n",
      " 90%|█████████ | 110/122 [36:20<03:55, 19.60s/it]\u001b[A\n",
      " 91%|█████████ | 111/122 [36:40<03:35, 19.60s/it]\u001b[A\n",
      " 92%|█████████▏| 112/122 [37:00<03:17, 19.75s/it]\u001b[A\n",
      " 93%|█████████▎| 113/122 [37:20<02:57, 19.73s/it]\u001b[A\n",
      " 93%|█████████▎| 114/122 [37:38<02:34, 19.27s/it]\u001b[A\n",
      " 94%|█████████▍| 115/122 [37:58<02:16, 19.48s/it]\u001b[A\n",
      " 95%|█████████▌| 116/122 [38:19<01:58, 19.82s/it]\u001b[A\n",
      " 96%|█████████▌| 117/122 [38:38<01:38, 19.66s/it]\u001b[A\n",
      " 97%|█████████▋| 118/122 [38:58<01:19, 19.85s/it]\u001b[A\n",
      " 98%|█████████▊| 119/122 [39:17<00:58, 19.65s/it]\u001b[A\n",
      " 98%|█████████▊| 120/122 [39:37<00:39, 19.57s/it]\u001b[A\n",
      " 18%|█▊        | 22/122 [07:11<32:16, 19.36s/it]\u001b[A\n",
      " 19%|█▉        | 23/122 [07:31<32:14, 19.54s/it]\u001b[A\n",
      " 20%|█▉        | 24/122 [07:51<32:12, 19.72s/it]\u001b[A\n",
      " 20%|██        | 25/122 [08:10<31:42, 19.61s/it]\u001b[A\n",
      " 21%|██▏       | 26/122 [08:29<31:03, 19.41s/it]\u001b[A\n",
      " 22%|██▏       | 27/122 [08:48<30:38, 19.35s/it]\u001b[A\n",
      " 23%|██▎       | 28/122 [09:07<29:55, 19.10s/it]\u001b[A\n",
      " 24%|██▍       | 29/122 [09:26<29:44, 19.19s/it]\u001b[A\n",
      " 25%|██▍       | 30/122 [09:46<29:28, 19.23s/it]\u001b[A\n",
      " 25%|██▌       | 31/122 [10:06<29:29, 19.45s/it]\u001b[A\n",
      " 26%|██▌       | 32/122 [10:25<29:08, 19.43s/it]\u001b[A\n",
      " 27%|██▋       | 33/122 [10:43<28:12, 19.01s/it]\u001b[A\n",
      " 28%|██▊       | 34/122 [11:03<28:17, 19.29s/it]\u001b[A\n",
      " 29%|██▊       | 35/122 [11:23<28:12, 19.46s/it]\u001b[A\n",
      " 30%|██▉       | 36/122 [11:42<27:49, 19.41s/it]\u001b[A\n",
      " 30%|███       | 37/122 [12:03<28:04, 19.82s/it]\u001b[A\n",
      " 31%|███       | 38/122 [12:21<26:59, 19.28s/it]\u001b[A\n",
      " 32%|███▏      | 39/122 [12:41<27:02, 19.55s/it]\u001b[A\n",
      " 33%|███▎      | 40/122 [13:01<26:50, 19.64s/it]\u001b[A\n",
      " 34%|███▎      | 41/122 [13:19<25:56, 19.22s/it]\u001b[A\n",
      " 34%|███▍      | 42/122 [13:39<25:58, 19.48s/it]\u001b[A\n",
      " 35%|███▌      | 43/122 [14:00<25:59, 19.75s/it]\u001b[A\n",
      " 36%|███▌      | 44/122 [14:19<25:30, 19.63s/it]\u001b[A\n",
      " 37%|███▋      | 45/122 [14:38<24:46, 19.31s/it]\u001b[A\n",
      " 38%|███▊      | 46/122 [14:57<24:22, 19.24s/it]\u001b[A\n",
      " 39%|███▊      | 47/122 [15:16<24:17, 19.43s/it]\u001b[A\n",
      " 39%|███▉      | 48/122 [15:36<24:09, 19.59s/it]\u001b[A\n",
      " 40%|████      | 49/122 [15:56<23:54, 19.65s/it]\u001b[A\n",
      " 41%|████      | 50/122 [16:15<23:15, 19.39s/it]\u001b[A\n",
      " 42%|████▏     | 51/122 [16:34<22:52, 19.34s/it]\u001b[A\n",
      " 43%|████▎     | 52/122 [16:54<22:38, 19.40s/it]\u001b[A\n",
      " 43%|████▎     | 53/122 [17:13<22:08, 19.26s/it]\u001b[A\n",
      " 44%|████▍     | 54/122 [17:32<21:44, 19.18s/it]\u001b[A\n",
      " 45%|████▌     | 55/122 [17:50<21:17, 19.06s/it]\u001b[A\n",
      " 46%|████▌     | 56/122 [18:10<21:11, 19.27s/it]\u001b[A\n",
      " 47%|████▋     | 57/122 [18:31<21:25, 19.78s/it]\u001b[A\n",
      " 48%|████▊     | 58/122 [18:50<20:45, 19.47s/it]\u001b[A\n",
      " 48%|████▊     | 59/122 [19:09<20:16, 19.30s/it]\u001b[A\n",
      " 49%|████▉     | 60/122 [19:27<19:27, 18.83s/it]\u001b[A\n",
      " 50%|█████     | 61/122 [19:46<19:28, 19.15s/it]\u001b[A\n",
      " 51%|█████     | 62/122 [20:05<19:01, 19.03s/it]\u001b[A\n",
      " 52%|█████▏    | 63/122 [20:25<18:49, 19.15s/it]\u001b[A\n",
      " 52%|█████▏    | 64/122 [20:42<18:05, 18.72s/it]\u001b[A\n",
      " 20%|██        | 2/10 [1:24:05<5:35:39, 2517.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.0590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/122 [00:19<39:38, 19.65s/it]\u001b[A\n",
      " 43%|████▎     | 52/122 [16:23<22:11, 19.01s/it]\u001b[A\n",
      " 90%|█████████ | 110/122 [34:17<03:41, 18.43s/it]\u001b[A\n",
      " 91%|█████████ | 111/122 [34:35<03:20, 18.25s/it]\u001b[A\n",
      " 92%|█████████▏| 112/122 [34:54<03:04, 18.50s/it]\u001b[A\n",
      " 93%|█████████▎| 113/122 [35:12<02:45, 18.44s/it]\u001b[A\n",
      " 93%|█████████▎| 114/122 [35:31<02:28, 18.57s/it]\u001b[A\n",
      " 94%|█████████▍| 115/122 [35:50<02:10, 18.61s/it]\u001b[A\n",
      " 95%|█████████▌| 116/122 [36:06<01:47, 17.84s/it]\u001b[A\n",
      " 40%|████      | 4/10 [2:43:40<4:02:47, 2427.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Loss: 0.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/122 [00:19<38:49, 19.25s/it]\u001b[A\n",
      " 49%|████▉     | 60/122 [18:05<18:30, 17.91s/it]\u001b[A\n",
      " 50%|█████     | 61/122 [18:23<18:12, 17.91s/it]\u001b[A\n",
      " 51%|█████     | 62/122 [18:40<17:45, 17.76s/it]\u001b[A\n",
      " 52%|█████▏    | 63/122 [18:58<17:31, 17.83s/it]\u001b[A\n",
      " 52%|█████▏    | 64/122 [19:18<17:47, 18.40s/it]\u001b[A\n",
      " 53%|█████▎    | 65/122 [19:35<17:12, 18.12s/it]\u001b[A\n",
      " 54%|█████▍    | 66/122 [19:54<17:06, 18.32s/it]\u001b[A\n",
      " 55%|█████▍    | 67/122 [20:14<17:10, 18.74s/it]\u001b[A\n",
      " 56%|█████▌    | 68/122 [20:32<16:48, 18.68s/it]\u001b[A\n",
      " 57%|█████▋    | 69/122 [20:49<16:03, 18.18s/it]\u001b[A\n",
      " 57%|█████▋    | 70/122 [21:07<15:38, 18.05s/it]\u001b[A\n",
      " 58%|█████▊    | 71/122 [21:27<15:45, 18.54s/it]\u001b[A\n",
      " 59%|█████▉    | 72/122 [21:43<14:52, 17.85s/it]\u001b[A\n",
      " 60%|█████▉    | 73/122 [22:00<14:20, 17.55s/it]\u001b[A\n",
      " 61%|██████    | 74/122 [22:20<14:33, 18.20s/it]\u001b[A\n",
      " 61%|██████▏   | 75/122 [22:39<14:34, 18.61s/it]\u001b[A\n",
      " 62%|██████▏   | 76/122 [22:58<14:23, 18.78s/it]\u001b[A\n",
      " 63%|██████▎   | 77/122 [23:16<13:45, 18.35s/it]\u001b[A\n",
      " 64%|██████▍   | 78/122 [23:32<13:04, 17.83s/it]\u001b[A\n",
      " 65%|██████▍   | 79/122 [23:50<12:48, 17.87s/it]\u001b[A\n",
      " 66%|██████▌   | 80/122 [24:08<12:26, 17.78s/it]\u001b[A\n",
      " 66%|██████▋   | 81/122 [24:25<12:06, 17.71s/it]\u001b[A\n",
      " 67%|██████▋   | 82/122 [24:45<12:09, 18.24s/it]\u001b[A\n",
      " 68%|██████▊   | 83/122 [25:03<11:54, 18.31s/it]\u001b[A\n",
      " 69%|██████▉   | 84/122 [25:22<11:43, 18.51s/it]\u001b[A\n",
      " 70%|██████▉   | 85/122 [25:41<11:23, 18.47s/it]\u001b[A\n",
      " 70%|███████   | 86/122 [25:58<10:49, 18.04s/it]\u001b[A\n",
      " 71%|███████▏  | 87/122 [26:16<10:38, 18.25s/it]\u001b[A\n",
      " 72%|███████▏  | 88/122 [26:36<10:30, 18.56s/it]\u001b[A\n",
      " 73%|███████▎  | 89/122 [26:53<10:00, 18.19s/it]\u001b[A\n",
      " 74%|███████▍  | 90/122 [27:11<09:41, 18.17s/it]\u001b[A\n",
      " 75%|███████▍  | 91/122 [27:30<09:28, 18.34s/it]\u001b[A\n",
      " 75%|███████▌  | 92/122 [27:47<09:03, 18.12s/it]\u001b[A\n",
      " 76%|███████▌  | 93/122 [28:05<08:38, 17.87s/it]\u001b[A\n",
      " 77%|███████▋  | 94/122 [28:23<08:22, 17.94s/it]\u001b[A\n",
      " 78%|███████▊  | 95/122 [28:41<08:02, 17.89s/it]\u001b[A\n",
      " 79%|███████▊  | 96/122 [28:58<07:37, 17.60s/it]\u001b[A\n",
      " 80%|███████▉  | 97/122 [29:17<07:34, 18.19s/it]\u001b[A\n",
      " 80%|████████  | 98/122 [29:34<07:10, 17.94s/it]\u001b[A\n",
      " 81%|████████  | 99/122 [29:51<06:43, 17.56s/it]\u001b[A\n",
      " 82%|████████▏ | 100/122 [30:08<06:19, 17.25s/it]\u001b[A\n",
      " 83%|████████▎ | 101/122 [30:24<05:58, 17.05s/it]\u001b[A\n",
      " 84%|████████▎ | 102/122 [30:41<05:38, 16.94s/it]\u001b[A\n",
      " 84%|████████▍ | 103/122 [30:59<05:25, 17.15s/it]\u001b[A\n",
      " 85%|████████▌ | 104/122 [31:18<05:19, 17.77s/it]\u001b[A\n",
      " 86%|████████▌ | 105/122 [31:35<05:01, 17.74s/it]\u001b[A\n",
      " 87%|████████▋ | 106/122 [31:53<04:43, 17.74s/it]\u001b[A\n",
      " 88%|████████▊ | 107/122 [32:11<04:25, 17.70s/it]\u001b[A\n",
      " 26%|██▌       | 32/122 [09:46<28:43, 19.15s/it]\u001b[A\n",
      " 34%|███▎      | 41/122 [12:34<25:28, 18.87s/it]\u001b[A\n",
      " 34%|███▍      | 42/122 [12:51<24:19, 18.25s/it]\u001b[A\n",
      " 35%|███▌      | 43/122 [13:09<24:07, 18.32s/it]\u001b[A\n",
      " 36%|███▌      | 44/122 [13:28<24:04, 18.52s/it]\u001b[A\n",
      " 37%|███▋      | 45/122 [13:48<24:15, 18.91s/it]\u001b[A\n",
      " 38%|███▊      | 46/122 [14:07<24:01, 18.97s/it]\u001b[A\n",
      " 39%|███▊      | 47/122 [14:25<23:08, 18.52s/it]\u001b[A\n",
      " 39%|███▉      | 48/122 [14:43<22:40, 18.39s/it]\u001b[A\n",
      " 40%|████      | 49/122 [15:01<22:06, 18.17s/it]\u001b[A\n",
      " 41%|████      | 50/122 [15:19<21:57, 18.30s/it]\u001b[A\n",
      " 42%|████▏     | 51/122 [15:37<21:24, 18.09s/it]\u001b[A\n",
      " 43%|████▎     | 52/122 [15:54<20:49, 17.85s/it]\u001b[A\n",
      " 43%|████▎     | 53/122 [16:12<20:38, 17.95s/it]\u001b[A\n",
      " 44%|████▍     | 54/122 [16:31<20:34, 18.15s/it]\u001b[A\n",
      " 45%|████▌     | 55/122 [16:49<20:21, 18.23s/it]\u001b[A\n",
      " 46%|████▌     | 56/122 [17:08<20:11, 18.35s/it]\u001b[A\n",
      " 47%|████▋     | 57/122 [17:27<20:15, 18.70s/it]\u001b[A\n",
      " 48%|████▊     | 58/122 [17:46<19:58, 18.72s/it]\u001b[A\n",
      " 48%|████▊     | 59/122 [18:03<18:58, 18.08s/it]\u001b[A\n",
      " 49%|████▉     | 60/122 [18:22<18:57, 18.34s/it]\u001b[A\n",
      " 50%|█████     | 61/122 [18:37<17:48, 17.52s/it]\u001b[A\n",
      " 51%|█████     | 62/122 [18:57<18:05, 18.09s/it]\u001b[A\n",
      " 52%|█████▏    | 63/122 [19:15<17:43, 18.03s/it]\u001b[A\n",
      " 52%|█████▏    | 64/122 [19:34<17:51, 18.48s/it]\u001b[A\n",
      " 53%|█████▎    | 65/122 [19:53<17:33, 18.47s/it]\u001b[A\n",
      " 54%|█████▍    | 66/122 [20:09<16:44, 17.94s/it]\u001b[A\n",
      " 55%|█████▍    | 67/122 [20:27<16:17, 17.77s/it]\u001b[A\n",
      " 56%|█████▌    | 68/122 [20:46<16:18, 18.12s/it]\u001b[A\n",
      " 57%|█████▋    | 69/122 [21:04<16:00, 18.13s/it]\u001b[A\n",
      " 57%|█████▋    | 70/122 [21:23<16:02, 18.51s/it]\u001b[A\n",
      " 58%|█████▊    | 71/122 [21:42<15:42, 18.49s/it]\u001b[A\n",
      " 59%|█████▉    | 72/122 [22:00<15:16, 18.33s/it]\u001b[A\n",
      " 60%|█████▉    | 73/122 [22:18<14:59, 18.36s/it]\u001b[A\n",
      " 61%|██████    | 74/122 [22:36<14:30, 18.14s/it]\u001b[A\n",
      " 61%|██████▏   | 75/122 [22:55<14:23, 18.38s/it]\u001b[A\n",
      " 62%|██████▏   | 76/122 [23:12<13:55, 18.16s/it]\u001b[A\n",
      " 63%|██████▎   | 77/122 [23:30<13:28, 17.97s/it]\u001b[A\n",
      " 64%|██████▍   | 78/122 [23:48<13:11, 18.00s/it]\u001b[A\n",
      " 65%|██████▍   | 79/122 [24:05<12:37, 17.62s/it]\u001b[A\n",
      " 66%|██████▌   | 80/122 [24:25<12:52, 18.40s/it]\u001b[A\n",
      " 66%|██████▋   | 81/122 [24:44<12:38, 18.51s/it]\u001b[A\n",
      " 67%|██████▋   | 82/122 [25:01<12:03, 18.10s/it]\u001b[A\n",
      " 68%|██████▊   | 83/122 [25:19<11:44, 18.07s/it]\u001b[A\n",
      " 69%|██████▉   | 84/122 [25:36<11:14, 17.75s/it]\u001b[A\n",
      " 70%|██████▉   | 85/122 [25:54<11:04, 17.97s/it]\u001b[A\n",
      " 70%|███████   | 86/122 [26:12<10:44, 17.90s/it]\u001b[A\n",
      " 71%|███████▏  | 87/122 [26:31<10:40, 18.31s/it]\u001b[A\n",
      " 72%|███████▏  | 88/122 [26:50<10:33, 18.62s/it]\u001b[A\n",
      " 73%|███████▎  | 89/122 [27:07<09:51, 17.93s/it]\u001b[A\n",
      " 74%|███████▍  | 90/122 [27:25<09:32, 17.90s/it]\u001b[A\n",
      " 75%|███████▍  | 91/122 [27:44<09:24, 18.21s/it]\u001b[A\n",
      " 75%|███████▌  | 92/122 [28:02<09:11, 18.38s/it]\u001b[A\n",
      " 76%|███████▌  | 93/122 [28:21<08:56, 18.49s/it]\u001b[A\n",
      " 48%|████▊     | 58/122 [17:45<19:36, 18.39s/it]\u001b[A\n",
      " 93%|█████████▎| 113/122 [34:02<02:41, 17.94s/it]\u001b[A\n",
      " 34%|███▍      | 42/122 [12:43<23:35, 17.69s/it]\u001b[A\n",
      " 79%|███████▊  | 96/122 [29:16<08:18, 19.16s/it]\u001b[A\n",
      " 80%|███████▉  | 97/122 [29:35<07:58, 19.12s/it]\u001b[A\n",
      " 80%|████████  | 98/122 [29:54<07:37, 19.08s/it]\u001b[A\n",
      " 81%|████████  | 99/122 [30:13<07:15, 18.93s/it]\u001b[A\n",
      " 82%|████████▏ | 100/122 [30:32<06:54, 18.86s/it]\u001b[A\n",
      " 83%|████████▎ | 101/122 [30:49<06:27, 18.43s/it]\u001b[A\n",
      " 84%|████████▎ | 102/122 [31:09<06:17, 18.89s/it]\u001b[A\n",
      " 84%|████████▍ | 103/122 [31:27<05:52, 18.53s/it]\u001b[A\n",
      " 85%|████████▌ | 104/122 [31:45<05:31, 18.43s/it]\u001b[A\n",
      " 86%|████████▌ | 105/122 [32:02<05:08, 18.15s/it]\u001b[A\n",
      " 87%|████████▋ | 106/122 [32:22<04:55, 18.46s/it]\u001b[A\n",
      " 88%|████████▊ | 107/122 [32:40<04:38, 18.57s/it]\u001b[A\n",
      " 89%|████████▊ | 108/122 [32:58<04:14, 18.19s/it]\u001b[A\n",
      " 89%|████████▉ | 109/122 [33:16<03:55, 18.08s/it]\u001b[A\n",
      " 90%|█████████ | 110/122 [33:35<03:40, 18.39s/it]\u001b[A\n",
      " 91%|█████████ | 111/122 [33:52<03:20, 18.19s/it]\u001b[A\n",
      " 92%|█████████▏| 112/122 [34:10<02:59, 17.93s/it]\u001b[A\n",
      " 93%|█████████▎| 113/122 [34:28<02:42, 18.07s/it]\u001b[A\n",
      " 93%|█████████▎| 114/122 [34:46<02:23, 17.92s/it]\u001b[A\n",
      " 94%|█████████▍| 115/122 [35:02<02:02, 17.57s/it]\u001b[A\n",
      " 95%|█████████▌| 116/122 [35:22<01:48, 18.13s/it]\u001b[A\n",
      " 96%|█████████▌| 117/122 [35:42<01:34, 18.88s/it]\u001b[A\n",
      " 97%|█████████▋| 118/122 [36:02<01:16, 19.09s/it]\u001b[A\n",
      " 98%|█████████▊| 119/122 [36:20<00:56, 18.76s/it]\u001b[A\n",
      " 98%|█████████▊| 120/122 [36:37<00:36, 18.22s/it]\u001b[A\n",
      " 99%|█████████▉| 121/122 [36:56<00:18, 18.35s/it]\u001b[A\n",
      "100%|██████████| 122/122 [36:59<00:00, 18.19s/it]\u001b[A\n",
      " 90%|█████████ | 9/10 [5:58:54<39:18, 2358.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Validation Loss: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/122 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/122 [00:19<39:37, 19.65s/it]\u001b[A\n",
      "  2%|▏         | 2/122 [00:38<38:27, 19.23s/it]\u001b[A\n",
      "  2%|▏         | 3/122 [00:56<37:13, 18.77s/it]\u001b[A\n",
      "  3%|▎         | 4/122 [01:16<37:25, 19.03s/it]\u001b[A\n",
      "  4%|▍         | 5/122 [01:34<36:33, 18.74s/it]\u001b[A\n",
      "  5%|▍         | 6/122 [01:53<36:17, 18.77s/it]\u001b[A\n",
      "  6%|▌         | 7/122 [02:11<35:24, 18.48s/it]\u001b[A\n",
      "  7%|▋         | 8/122 [02:29<35:00, 18.42s/it]\u001b[A\n",
      "  7%|▋         | 9/122 [02:47<34:36, 18.37s/it]\u001b[A\n",
      "  8%|▊         | 10/122 [03:05<34:11, 18.31s/it]\u001b[A\n",
      "  9%|▉         | 11/122 [03:22<33:06, 17.90s/it]\u001b[A\n",
      " 10%|▉         | 12/122 [03:42<33:39, 18.36s/it]\u001b[A\n",
      " 11%|█         | 13/122 [04:00<33:12, 18.28s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss = outputs.loss\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Validation Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "529d4cef-818c-4677-b4ce-6dcc762e00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '../model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dfe3f435-a82f-4a76-9c56-7d002d386ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = torch.load('../model.pt')\n",
    "#model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f9b1b9d-f912-42dc-81b8-f263d0633e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input text\n",
    "input_text = val_input_texts[0]\n",
    "sql = val_target_queries[0]\n",
    "# Tokenize and encode input text\n",
    "tokens = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "# tokens_label = tokenizer(label_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5ed7ada-ad79-4bce-9f6d-5332c77678be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Predicted Query:  SELECT T1.first_name, T1.middle_name, T1.last_name, count(*) FROM Students AS T1 JOIN Student_Enrolment_Enrolment AS T2 ON T1.student_id = T2.student_id GROUP BY T1.student_id ORDER BY count(*) DESC LIMIT 1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Actual Query:  SELECT T1.student_id ,  T1.first_name ,  T1.middle_name ,  T1.last_name ,  count(*) ,  T1.student_id FROM Students AS T1 JOIN Student_Enrolment AS T2 ON T1.student_id  =  T2.student_id GROUP BY T1.student_id ORDER BY count(*) DESC LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "outputs = saved_model.generate(input_ids=tokens.input_ids, max_new_tokens = 512)\n",
    "predicted_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# print(\"Input Text: \", input_text)\n",
    "print('-'*100)\n",
    "print(\"Predicted Query: \", predicted_query)\n",
    "print('-'*100)\n",
    "print(\"Actual Query: \", sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cad4a-b179-4f12-b413-d2cd6310e892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
