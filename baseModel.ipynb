{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6be35e-aaf8-4750-93e5-f4076ba7a73f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/opt/conda/lib/python3.7/site-packages/nvidia/cublas/lib/libcublas.so.11: symbol cublasLtHSHMatmulAlgoInit version libcublasLt.so.11 not defined in file libcublasLt.so.11 with link time reference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.7/site-packages/torch/lib/../../nvidia/cublas/lib/libcublas.so.11: symbol cublasLtHSHMatmulAlgoInit version libcublasLt.so.11 not defined in file libcublasLt.so.11 with link time reference",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_16556/1561314447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# See Note [Global dependencies]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'libcublas.so.11'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_preload_cuda_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_preload_cuda_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcublas_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcudnn_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /opt/conda/lib/python3.7/site-packages/nvidia/cublas/lib/libcublas.so.11: symbol cublasLtHSHMatmulAlgoInit version libcublasLt.so.11 not defined in file libcublasLt.so.11 with link time reference"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e0cead-4501-4614-8b39-3ec47cdfd09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>TQL</th>\n",
       "      <th>SQL</th>\n",
       "      <th>dataset</th>\n",
       "      <th>fileName</th>\n",
       "      <th>filePath</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_management</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>train</td>\n",
       "      <td>department_management.sqlite</td>\n",
       "      <td>sqliteDB/department_management.sqlite</td>\n",
       "      <td>{'count(*)': {0: 5}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   db_id                                                TQL  \\\n",
       "0  department_management  How many heads of the departments are older th...   \n",
       "\n",
       "                                          SQL dataset  \\\n",
       "0  SELECT count(*) FROM head WHERE age  >  56   train   \n",
       "\n",
       "                       fileName                               filePath  \\\n",
       "0  department_management.sqlite  sqliteDB/department_management.sqlite   \n",
       "\n",
       "                 result  \n",
       "0  {'count(*)': {0: 5}}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schema_id</th>\n",
       "      <th>table_name</th>\n",
       "      <th>table_name_original</th>\n",
       "      <th>primary_key</th>\n",
       "      <th>column_list</th>\n",
       "      <th>column_list_original</th>\n",
       "      <th>column_datatypes</th>\n",
       "      <th>foreign_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perpetrator</td>\n",
       "      <td>perpetrator</td>\n",
       "      <td>perpetrator</td>\n",
       "      <td>Perpetrator_ID</td>\n",
       "      <td>['perpetrator id', 'people id', 'date', 'year'...</td>\n",
       "      <td>['Perpetrator_ID', 'People_ID', 'Date', 'Year'...</td>\n",
       "      <td>['number', 'number', 'text', 'number', 'text',...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perpetrator</td>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>People_ID</td>\n",
       "      <td>['people id', 'name', 'height', 'weight', 'hom...</td>\n",
       "      <td>['People_ID', 'Name', 'Height', 'Weight', 'Hom...</td>\n",
       "      <td>['number', 'text', 'number', 'number', 'text']</td>\n",
       "      <td>[['perpetrator', 'People_ID', 'people', 'Peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     schema_id   table_name table_name_original     primary_key  \\\n",
       "0  perpetrator  perpetrator         perpetrator  Perpetrator_ID   \n",
       "1  perpetrator       people              people       People_ID   \n",
       "\n",
       "                                         column_list  \\\n",
       "0  ['perpetrator id', 'people id', 'date', 'year'...   \n",
       "1  ['people id', 'name', 'height', 'weight', 'hom...   \n",
       "\n",
       "                                column_list_original  \\\n",
       "0  ['Perpetrator_ID', 'People_ID', 'Date', 'Year'...   \n",
       "1  ['People_ID', 'Name', 'Height', 'Weight', 'Hom...   \n",
       "\n",
       "                                    column_datatypes  \\\n",
       "0  ['number', 'number', 'text', 'number', 'text',...   \n",
       "1     ['number', 'text', 'number', 'number', 'text']   \n",
       "\n",
       "                                        foreign_keys  \n",
       "0                                                 []  \n",
       "1  [['perpetrator', 'People_ID', 'people', 'Peopl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queryData = pd.read_csv('gs://data_tql/spider/processed/spiderQueryData.csv')\n",
    "tableData = pd.read_csv('gs://data_tql/spider/processed/Schemas/tablesSchemaSpider.csv')\n",
    "\n",
    "display(queryData.head(1))\n",
    "display(tableData.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bdd497-3c7c-42a2-809a-0f96a981a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema_natural_language(row):\n",
    "\n",
    "    schema_id = row['schema_id']\n",
    "    table_name = row['table_name']\n",
    "    primary_key = row['primary_key']\n",
    "    column_list = eval(row['column_list_original'])\n",
    "    datatype_list = eval(row['column_datatypes'])\n",
    "    foreign_key = eval(row['foreign_keys'])\n",
    "\n",
    "    column_list_with_datatype = []\n",
    "    for column, datatype in zip(column_list, datatype_list):\n",
    "        column_list_with_datatype.append(' has datatype '.join([column, datatype]))\n",
    "\n",
    "    schema_natural_language = f\"Given the Table {table_name} having columns as {', '.join(column_list_with_datatype)} which has {primary_key}\"\n",
    "    return schema_natural_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57110a2-994a-41dc-9f00-0905aa888101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('How many heads of the departments are older than 56 ? Given the Table department having columns as Department_ID has datatype number, Name has datatype text, Creation has datatype text, Ranking has datatype number, Budget_in_Billions has datatype number, Num_Employees has datatype number which has Department_ID and Given the Table head having columns as head_ID has datatype number, name has datatype text, born_state has datatype text, age has datatype number which has head_ID and Given the Table management having columns as department_ID has datatype number, head_ID has datatype number, temporary_acting has datatype text which has department_ID',\n",
       " 'SELECT count(*) FROM head WHERE age  >  56')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableData['schema_natural_language'] = tableData.apply(create_schema_natural_language, axis = 1)\n",
    "tableData.head(3)\n",
    "\n",
    "all_schemas = tableData['schema_id'].unique()\n",
    "schema_table_query = {}\n",
    "for schema in all_schemas:\n",
    "    schema_details = ' and '.join(tableData[tableData['schema_id'] == schema]['schema_natural_language'].values)\n",
    "    schema_table_query[schema] = schema_details\n",
    "\n",
    "queryData['schema_natural_language'] = queryData['db_id'].map(schema_table_query)\n",
    "queryData['final_TQL'] = queryData['TQL'] + ' ' + queryData['schema_natural_language']\n",
    "queryData.head(2)\n",
    "\n",
    "queryData['final_TQL'][0], queryData['SQL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4aefe3-4f6e-4de0-b942-ddd9efff6f79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T5Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_16556/3593207473.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the pretrained T5 model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't5-small'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T5Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the pretrained T5 model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a2cd6-0331-4eab-84fc-3ac081e7fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset for training\n",
    "class SQLDataset(Dataset):\n",
    "    def __init__(self, input_texts, target_queries, tokenizer, task_prefix):\n",
    "        self.input_texts = input_texts\n",
    "        self.target_queries = target_queries\n",
    "        self.tokenizer = tokenizer\n",
    "        self.task_prefix = task_prefix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        input_text = self.task_prefix + self.input_texts[index]\n",
    "        target_query = self.target_queries[index]\n",
    "\n",
    "        input_encoding = self.tokenizer([input_text], return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        target_encoding = self.tokenizer([target_query], return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.squeeze(0),\n",
    "            'attention_mask': input_encoding.attention_mask.squeeze(0),\n",
    "            'labels': target_encoding.input_ids.squeeze(0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f7d609-cbde-46d0-935c-a39118708144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labeled dataset\n",
    "input_texts = queryData['final_TQL'].values # List of input texts\n",
    "target_queries = queryData['SQL'].values  # List of corresponding target SQL queries\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_input_texts, val_input_texts, train_target_queries, val_target_queries = train_test_split(input_texts, target_queries, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff750c0a-5be6-466f-9577-efae403074fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instances of the custom dataset\n",
    "task_prefix = 'Generate an SQL Query for '\n",
    "train_dataset = SQLDataset(train_input_texts, train_target_queries, tokenizer, task_prefix)\n",
    "val_dataset = SQLDataset(val_input_texts, val_target_queries, tokenizer, task_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c277ade-2403-4a3a-be4d-a55ab8a45701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec231dca-c416-4bc1-9f5c-ab598ca23098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a5afd-0be9-4ebd-b8fb-217a3c2e7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss = outputs.loss\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "# Fine-tuning completed, you can now use the trained model for generating SQL queries\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
