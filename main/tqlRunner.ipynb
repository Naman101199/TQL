{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf71172-60af-40ab-9d88-6e25e71750a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../queryProcessing/')\n",
    "\n",
    "from utils import *\n",
    "from TableMapper import TableMapper\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer, pipeline\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import json\n",
    "\n",
    "class TQLRunner():\n",
    "    \n",
    "    def __init__(self, schema_id):\n",
    "        \n",
    "        if(schema_id is None):\n",
    "            raise Exception(\"Schema ID is needed\")\n",
    "        \n",
    "        self.query, self.schema = get_spider_schema_table_files()\n",
    "        self.tableMapper = TableMapper(self.query, self.schema)\n",
    "        \n",
    "        self.s, self.t = self.tableMapper.get_filtered_schema(schema_id)\n",
    "        \n",
    "        print('All libraries loaded')\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        print(\"Helloj\")\n",
    "        # Load the adapter configuration from the provided URL\n",
    "        adapter_config_url = 'https://huggingface.co/naman1011/TQL/raw/main/adapter_config.json'\n",
    "        adapter_config = json.loads('''{\n",
    "                          \"auto_mapping\": null,\n",
    "                          \"base_model_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                          \"bias\": \"none\",\n",
    "                          \"fan_in_fan_out\": false,\n",
    "                          \"inference_mode\": true,\n",
    "                          \"init_lora_weights\": true,\n",
    "                          \"layers_pattern\": null,\n",
    "                          \"layers_to_transform\": null,\n",
    "                          \"lora_alpha\": 32,\n",
    "                          \"lora_dropout\": 0.1,\n",
    "                          \"modules_to_save\": null,\n",
    "                          \"peft_type\": \"LORA\",\n",
    "                          \"model_type\" : \"t5\",\n",
    "                          \"r\": 2,\n",
    "                          \"revision\": null,\n",
    "                          \"target_modules\": [\n",
    "                                \"q_proj\",\n",
    "                                \"v_proj\"\n",
    "                  ],\n",
    "                  \"task_type\": \"CASUAL_LM\"\n",
    "            }'''\n",
    "       )\n",
    "        \n",
    "        # Load the model using the adapter configuration\n",
    "        print(adapter_config)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained('naman1011/TQL', config=adapter_config)\n",
    "        print(\"Hello 4j\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('naman1011/TQL')\n",
    "        print(\"Hello kfr4j\")\n",
    "            \n",
    "        print('LLM Model initialized')\n",
    "            \n",
    "        \n",
    "    def create_schema_natural_language(self, row):\n",
    "\n",
    "        schema_id = row['schema_id']\n",
    "        table_name = row['table_name']\n",
    "        primary_key = row['primary_key']\n",
    "        column_list = eval(row['column_list_original'])\n",
    "        datatype_list = eval(row['column_datatypes'])\n",
    "        foreign_key = eval(row['foreign_keys'])\n",
    "\n",
    "        column_list_with_datatype = []\n",
    "        for column, datatype in zip(column_list, datatype_list):\n",
    "            column_list_with_datatype.append(\\\n",
    "                     ' has datatype '.join([column, datatype])\n",
    "            )\n",
    "\n",
    "        schema_natural_language = \\\n",
    "                f\"Given the Table {table_name} having columns as \\\n",
    "                        {', '.join(column_list_with_datatype)} \\\n",
    "                            which has {primary_key}\"\n",
    "        return schema_natural_language\n",
    "    \n",
    "    \n",
    "    def get_table_prompt(self, input_text):\n",
    "        \n",
    "        table_names_from_tql = self.tableMapper.get_table_names_tql(self.s, input_text)\n",
    "        \n",
    "        if(len(table_names_from_tql) == 0):\n",
    "            raise Exception(\"No tables found, please repharse the query and try again\")\n",
    "        \n",
    "        prompt_tables = []\n",
    "        for i in table_names_from_tql:\n",
    "            prompt_tables.append(\n",
    "                self.s[self.s['table_name_original'] == i].apply(\n",
    "                    self.create_schema_natural_language, axis = 1\n",
    "                ).reset_index(drop = True).iloc[0]\n",
    "            )\n",
    "                \n",
    "        return ' and '.join(prompt_tables)\n",
    "    \n",
    "    \n",
    "    def get_final_prompt(self, input_text):\n",
    "        \n",
    "        task_prefix = 'Generate an SQL Query for'\n",
    "        table_prompt = self.get_table_prompt(input_text)\n",
    "        \n",
    "        final_prompt = task_prefix + ' ' + input_text + ' ' + table_prompt\n",
    "        \n",
    "        return final_prompt\n",
    "        \n",
    "        \n",
    "    def get_SQL_query(self, input_text):\n",
    "        \n",
    "        prompt = self.get_final_prompt(input_text)\n",
    "        print(prompt)\n",
    "        \n",
    "        tokens = self.tokenizer(prompt, \n",
    "                           return_tensors=\"pt\", max_length=512, \n",
    "                           truncation=True, padding=\"max_length\")\n",
    "        \n",
    "        outputs = self.model.generate(input_ids=tokens.input_ids.to(self.device), max_new_tokens = 512)\n",
    "        predicted_query = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return predicted_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349dfc11-d728-4c3c-9537-c331549aaf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded\n",
      "Helloj\n",
      "{'auto_mapping': None, 'base_model_name_or_path': 'meta-llama/Llama-2-7b-chat-hf', 'bias': 'none', 'fan_in_fan_out': False, 'inference_mode': True, 'init_lora_weights': True, 'layers_pattern': None, 'layers_to_transform': None, 'lora_alpha': 32, 'lora_dropout': 0.1, 'modules_to_save': None, 'peft_type': 'LORA', 'model_type': 't5', 'r': 2, 'revision': None, 'target_modules': ['q_proj', 'v_proj'], 'task_type': 'CASUAL_LM'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087db8b075f7442288e4d06ed9b04b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jasme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jasme\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 tqlRunner = TQLRunner(<span style=\"color: #808000; text-decoration-color: #808000\">'yelp'</span>)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 │   │   # Load the model using the adapter configuration</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(adapter_config)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 63 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model = AutoModelForCausalLM.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">'naman1011/TQL'</span>, config=adapte   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Hello 4j\"</span>)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer = AutoTokenizer.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">'naman1011/TQL'</span>)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Hello kfr4j\"</span>)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\jasme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\aut</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">o\\auto_factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">568</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">565 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_class.from_pretrained(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">566 │   │   │   │   </span>pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">567 │   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>568 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">569 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Unrecognized configuration class {</span>config.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span><span style=\"color: #808000; text-decoration-color: #808000\">} for this kind of AutoM</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">570 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Model type should be one of {', '</span>.join(c.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span>c<span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapp   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">571 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Unrecognized configuration class <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'transformers.models.t5.configuration_t5.T5Config'</span><span style=\"font-weight: bold\">&gt;</span> for this \n",
       "kind of AutoModel: AutoModelForCausalLM.\n",
       "Model type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, \n",
       "BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, \n",
       "CpmAntConfig, CTRLConfig, Data2VecTextConfig, ElectraConfig, ErnieConfig, FalconConfig, GitConfig, GPT2Config, \n",
       "GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, LlamaConfig, \n",
       "MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MptConfig, MusicgenConfig, MvpConfig, \n",
       "OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PLBartConfig, ProphetNetConfig, \n",
       "QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, \n",
       "RoFormerConfig, RwkvConfig, Speech2Text2Config, TransfoXLConfig, TrOCRConfig, XGLMConfig, XLMConfig, \n",
       "XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 tqlRunner = TQLRunner(\u001b[33m'\u001b[0m\u001b[33myelp\u001b[0m\u001b[33m'\u001b[0m)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load the model using the adapter configuration\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(adapter_config)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model = AutoModelForCausalLM.from_pretrained(\u001b[33m'\u001b[0m\u001b[33mnaman1011/TQL\u001b[0m\u001b[33m'\u001b[0m, config=adapte   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mHello 4j\u001b[0m\u001b[33m\"\u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.tokenizer = AutoTokenizer.from_pretrained(\u001b[33m'\u001b[0m\u001b[33mnaman1011/TQL\u001b[0m\u001b[33m'\u001b[0m)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mHello kfr4j\u001b[0m\u001b[33m\"\u001b[0m)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\jasme\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\aut\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mo\\auto_factory.py\u001b[0m:\u001b[94m568\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m model_class.from_pretrained(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m566 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m568 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUnrecognized configuration class \u001b[0m\u001b[33m{\u001b[0mconfig.\u001b[91m__class__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m for this kind of AutoM\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m570 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mModel type should be one of \u001b[0m\u001b[33m{\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m.join(c.\u001b[91m__name__\u001b[0m\u001b[90m \u001b[0m\u001b[94mfor\u001b[0m\u001b[90m \u001b[0mc\u001b[90m \u001b[0m\u001b[95min\u001b[0m\u001b[90m \u001b[0m\u001b[96mcls\u001b[0m._model_mapp   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mUnrecognized configuration class \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'transformers.models.t5.configuration_t5.T5Config'\u001b[0m\u001b[1m>\u001b[0m for this \n",
       "kind of AutoModel: AutoModelForCausalLM.\n",
       "Model type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, \n",
       "BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, LlamaConfig, CodeGenConfig, \n",
       "CpmAntConfig, CTRLConfig, Data2VecTextConfig, ElectraConfig, ErnieConfig, FalconConfig, GitConfig, GPT2Config, \n",
       "GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTNeoXJapaneseConfig, GPTJConfig, LlamaConfig, \n",
       "MarianConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MptConfig, MusicgenConfig, MvpConfig, \n",
       "OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PLBartConfig, ProphetNetConfig, \n",
       "QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, \n",
       "RoFormerConfig, RwkvConfig, Speech2Text2Config, TransfoXLConfig, TrOCRConfig, XGLMConfig, XLMConfig, \n",
       "XLMProphetNetConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqlRunner = TQLRunner('yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53e13c-8c48-4103-ac3b-b3113af611a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'How many reviews are there in the database'\n",
    "tqlRunner.get_SQL_query(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abb6e8-0a3b-46bb-8ae3-908d916551e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'How many businesses are there in \"Vegas\"'\n",
    "tqlRunner.get_SQL_query(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7bb78-9c78-4926-ac7b-d3481f62d698",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a835b7f-333e-4662-a6ee-c74a00c0bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqlRunner = TQLRunner('college_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d7927-5da2-43da-bda7-ba8fbf4242c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'What is the name and building of the departments whose budget is more than the average budget?'\n",
    "tqlRunner.get_SQL_query(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160136d-1a48-40de-b244-5c5731ef15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'What are the names of students who have taken the prerequisite for the course \"International Finance\"?'\n",
    "tqlRunner.get_SQL_query(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f587f-8935-450f-8ed5-a1f0ce59c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaModel, LlamaConfig\n",
    "\n",
    "# Initializing a LLaMA llama-7b style configuration\n",
    "configuration = LlamaConfig()\n",
    "\n",
    "# Initializing a model from the llama-7b style configuration\n",
    "model = LlamaModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63056e6e-ddab-4b4e-a5e2-45c02339110a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
