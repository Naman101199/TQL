{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eea53f9-3809-4540-9075-6dde734412f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from google.cloud import storage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89efbb25-2c10-421d-885a-850d3ad88e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs(bucket_name, folder_name):\n",
    "    \"\"\"List all files in given COS directory.\"\"\"    \n",
    "    blob_names = []\n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "    for blob in blobs:\n",
    "        blob_names.append(blob.name)\n",
    "    return blob_names\n",
    "    \n",
    "def list_blobs_pd(bucket_name, folder_name):\n",
    "    \"\"\"List all files in given COS directory.\"\"\"       \n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "\n",
    "    blob_name = []\n",
    "    blob_size = []\n",
    "    blob_time = []\n",
    "    \n",
    "    for blob in blobs:\n",
    "        blob_name.append(blob.name)\n",
    "        blob_size.append(blob.size)\n",
    "        blob_time.append(blob.time_created)\n",
    "\n",
    "    blobs_df = pd.DataFrame(list(zip(blob_name, blob_size, blob_time)), columns=['filePath', 'size', 'timeStamp'])    \n",
    "    return blobs_df\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from COS bucket.\"\"\"\n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"    \n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bbb95a6-33fe-45e9-ad9a-752515ffed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = list_blobs_pd(BUCKET_NAME, FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33be8e1c-1ed9-4c78-82c2-92f0b2a825dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wikisqliteDB/test/']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_blobs(BUCKET_NAME, FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcb218f1-47ae-4212-b579-27ab8b9208b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a376ba35-e0ee-43a6-9ab9-a2a6bc2e2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = dataset_type + \".db\"\n",
    "BUCKET_NAME = \"data_tql\"\n",
    "FOLDER_NAME = \"WikiSQL/data\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(f\"{FOLDER_NAME}/{DB_NAME}\")\n",
    "\n",
    "# Download the SQLite file to a local file\n",
    "local_file_name = DB_NAME\n",
    "blob.download_to_filename(local_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d00a21a6-144c-4f23-aa53-0e29b04cecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME = \"wikisqliteDB/\"+dataset_type\n",
    "\n",
    "# connect to the database file\n",
    "conn = sqlite3.connect(local_file_name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# extract the table names from the database\n",
    "table_names = [row[0] for row in cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f40e9379-7357-47b8-8a55-b73fc7eb7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a separate SQLite file for each table\n",
    "failed_schemas = []\n",
    "for table_name in table_names:\n",
    "    try:\n",
    "        # extract the schema for the table\n",
    "        schema = \"\".join(row[0] + \"\\n\" for row in cursor.execute(f\"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'\").fetchall())\n",
    "\n",
    "        # extract the rows for the table\n",
    "        rows = cursor.execute(f\"SELECT * FROM {table_name}\").fetchall()\n",
    "\n",
    "        # create a new SQLite file for the table\n",
    "        new_db_name = f\"{table_name}.sqlite\"\n",
    "        new_conn = sqlite3.connect(new_db_name)\n",
    "        new_cursor = new_conn.cursor()\n",
    "\n",
    "        # create the table in the new SQLite file using the extracted schema\n",
    "        new_cursor.execute(schema)\n",
    "\n",
    "        # insert the rows into the new SQLite file\n",
    "        for row in rows:\n",
    "            values = \",\".join([f\"'{str(val)}'\" for val in row])\n",
    "            new_cursor.execute(f\"INSERT INTO {table_name} VALUES ({values})\")\n",
    "\n",
    "        # save and close the new SQLite file\n",
    "        new_conn.commit()\n",
    "        new_conn.close()\n",
    "\n",
    "        # upload the new SQLite file to the GCP bucket\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(BUCKET_NAME)\n",
    "        blob = bucket.blob(f\"{FOLDER_NAME}/{new_db_name}\")\n",
    "        blob.upload_from_filename(new_db_name)\n",
    "    except:\n",
    "        failed_schemas.append(table_name)\n",
    "    \n",
    "# close the connection to the original database file\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5571ff79-56a4-4560-b20b-8a952a3dadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# specify the folder path where the SQLite files are located\n",
    "folder_path = \"/home/jupyter/TQL/databaseDesign/WikiSQL\"\n",
    "\n",
    "# loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # check if the file is a SQLite file (i.e., has .db or .sqlite extension)\n",
    "    if filename.endswith(\".db\") or filename.endswith(\".sqlite\"):\n",
    "        # delete the file\n",
    "        os.remove(os.path.join(folder_path, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "acc8720a-64d3-49c2-9f61-686a3d71bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f35e64c9-c3c9-4e1b-b7b8-694efbffe7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"failed_schemas.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"failed_schema\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for schema in failed_schemas:\n",
    "        writer.writerow({\"failed_schema\": schema})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b074f1ef-3f7e-481e-9979-b0d1816577af",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"failed_schemas.csv\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(f\"{FOLDER_NAME}/{file_name}\")\n",
    "blob.upload_from_filename(\"failed_schemas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d23ea6ff-eb0e-4eec-8913-6ecf38ef9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(folder_path):\n",
    "    # check if the file is a SQLite file (i.e., has .db or .sqlite extension)\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # delete the file\n",
    "        os.remove(os.path.join(folder_path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c1abd-6451-4511-9f22-552cbe134ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
